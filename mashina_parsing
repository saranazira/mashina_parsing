import requests
from bs4 import BeautifulSoup
import csv

def write_to_csv(data):
    with open('mashina.csv', 'a') as file:
        writer = csv.writer(file)
        writer.writerow([data ['title'], data['price'], data['img'], data['description']])

def get_html(url):
    response = requests.get(url)
    return response.text

def get_total_pages(html):
    soup = BeautifulSoup(html, 'lxml')
    page_list = soup.find('div', class_='pages fl').find_all('a')
    last_page = page_list[-1].text
    return last_page

def get_data(html):
    soup = BeautifulSoup(html, 'lxml')
    cars = soup.find('div', class_='table-view-list').find_all('a', class_='list-item list-label')
    for car in cars:
        try:
            title = car.find('span', class_='block name').text.strip()
        except:
                title = ''
        try: 
            price = car.find('span', class_='block price').text
        except:
            price = ''
        try:
            img = car.find('img', class_='image-wrap').get('src')
        except:
            img = ''
        try:
            description = car.find('description', class_= 'block info-wrapper item-info-wrapper')
        except:
            description = ''

        data = {
            'title':title,
            'price': price,
            'img': img,
            'description': description
        }

        write_to_csv(data)
def main():
    url_= 'https://www.mashina.kg/search'
    html = get_html(url_)
    number = int(get_total_pages(html))
    i = 1
    while i <= number:
        print(i)
        url_= f'https://www.mashina.kg/search/{i}'
        html = get_html(url_)
        number = int(get_total_pages(html))
        if not BeautifulSoup(html, 'lxml').find('div', class_='table-view-list'):
            break

        get_data(html)
        i+=1
with open('mashina.csv', 'w') as file:
    writer = csv.writer(file)
    writer.writerow(['title','price', 'img', 'description'])

main()